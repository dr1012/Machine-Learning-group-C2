import numpy as np
import csv
import math
import operator
import matplotlib.pyplot as plt
import itertools

from knn_regression_subsets import multi_knn

###################################################################################################################################
#This code has been based on:
#Title:Tutorial To Implement k-Nearest Neighbors in Python From Scratch
#Author:Jason Brownlee
#Date:September 12, 2014
#Link:https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/
###################################################################################################################################




def main_knn_function():
    with open('final_training_data.csv', 'r') as csvfile:
            datareader = csv.reader(csvfile, delimiter=',')
            header = next(datareader)
            data = []
        

            for row in datareader:
                row_of_floats = list(map(float, row))
                data.append(row_of_floats)

    data_as_nparray = np.array(data)

    size  = len(data_as_nparray)
    train_size_float =  (0.8*size)

    train_size = int(train_size_float)





    internal_training_data_as_nparray = data_as_nparray[0:train_size]


    internal_test_data_as_nparray = data_as_nparray[train_size:]








    def euclideanDistance(instance1, instance2, length):
        distance = 0
        for x in range(length):
            #this will give the sum of the squares of the distance between the 2 points in all the dimensions. 
            distance += pow((instance1[x]-instance2[x]), 2)
            # this will give us the Euclidean distance in (length) dimensions. 
        return math.sqrt(distance)

    def getNeighbors(trainingSet, testInstance, k):
        distances =  []
        #testInstance is a list representing a single point (single row in table). 
        #length is the number of dimensions
        length = len(testInstance)-1
        #for each row in training set
        #find the eculidean distance over all dimensions for that point 
        #the distances list will contain the distances between the test poiint and all the training points.
        #Actually it will contain the traininSet point (a list of all parameters) and the distance
        #then we sort it from smallest to largest distance
        for x in range(len(trainingSet)):
            dist = euclideanDistance(testInstance, trainingSet[x], length)
            distances.append((trainingSet[x], dist))
        distances.sort(key=operator.itemgetter(1))
        neighbors = []
        for x in range(k):
            # neighbors is a list that will contain the data-points [list of parameters] of the k nearest points
            neighbors.append(distances[x][0])
        return neighbors


    def getResponse(neighbors,k):
        #a dictionary containing the different claasses and the number of neighbors that belong to that class
        total_sum = 0
        for x in range(len(neighbors)):
            response = neighbors[x][-1]
            total_sum += response
        return total_sum/k    
    # In case of a  draw this selects one response, ideally we would select an ubiased random response.


    #  Simple function that evaluates rms error of predictions
    def rmsError(testSet, predictions):
        errors = []
        for x in range(len(testSet)):
            error = (testSet[x][-1]-predictions[x])
            errors.append(error**2) 
        rms_error =  math.sqrt(np.mean(errors))
        return rms_error
    

    #########getting the inidividual atribute KNN models##########################
    total_minErrors_and_optimmal_k = []

    for a in range(0,11):

            trainingSubset = internal_training_data_as_nparray[:][:,[a,11]]
            trainingSubsetList = trainingSubset.tolist()


            validationSubset  = internal_test_data_as_nparray[:][:,[a,11]]
            ValidationSubsetList =  validationSubset.tolist()

            max_neighbours = 150
            accuracies = []

            

            for y in range(1,max_neighbours):

                predictions = []
                for x in range(len(internal_test_data_as_nparray)):
                    neighbors = getNeighbors(trainingSubsetList, ValidationSubsetList[x], y)
                    result = getResponse(neighbors,y)
                    predictions.append(result)
                
                    
                accuracy = rmsError(internal_test_data_as_nparray, predictions)
                

                accuracies.append([y,accuracy])

            npAcurracies = np.array(accuracies)

            
            min_error = np.min(npAcurracies[:,1:2])
            min_index = np.argmin(npAcurracies[:,1:2])
            K_min_error = npAcurracies[min_index][0]

            total_minErrors_and_optimmal_k.append([float(a), min_error, float(K_min_error)])

            fig = plt.figure()
            ax = fig.add_subplot(1,1,1)
            ax.plot(npAcurracies[:,0:1],npAcurracies[:,1:2])
            ax.set_ylim(None,1)
            ax.set_xlabel("K")
            ax.set_ylabel("$E_{RMS}$")
            ax.set_title("KNN for " + header[a] +" ,minimum error: " + str(min_error) + " at K = " + str(K_min_error)  ,fontsize = 8)
            fig.savefig("KNN_inidividual_"+header[a]+".pdf", fmt="pdf")
            

    ################find the best 4 attributes and generating all possible subets####################


    #array contains [attribute number, minimum error, k for minimum error]

    np_individual_errors_array =  np.array(total_minErrors_and_optimmal_k)
    print(np_individual_errors_array)


    #sorted array by which attribute has the smallest error
    sorted_array = np_individual_errors_array[np_individual_errors_array[:,1].argsort()]


    # taking the  best 4 attributes as a subset
    subset_array = sorted_array[0:4]

    subset_attributes =  (subset_array[:][:,0:1]).flatten()


    ############testing all combinations of the subset of the best attributes ###################################
    subset_error_k = []
    for L in range(0, len(subset_attributes)+1):
        for subset in itertools.combinations(subset_attributes, L):
    #every subset here is a tuple containing the indexes of the attributes in the subset
            if(len(subset)>1):
                print(subset)
                subset_list_temp = list(subset)
                subset_list =[int(i) for i in subset_list_temp]
                subset_error_k.append(multi_knn(subset_list,internal_training_data_as_nparray,internal_test_data_as_nparray,150))

    final_array = np.array(subset_error_k)

    print(final_array)

    sorted_final_array = final_array[final_array[:,1].argsort()]

    print(sorted_final_array)

    if (subset_array[0][1])<=(sorted_final_array[0][1]):
        print("best KNN regression subset, error, k: " + str(subset_array[0]))
        return subset_array[0]
    else:
        print("best KNN regression subset, error, k: " + str(sorted_final_array[0]))
        return sorted_final_array[0]
